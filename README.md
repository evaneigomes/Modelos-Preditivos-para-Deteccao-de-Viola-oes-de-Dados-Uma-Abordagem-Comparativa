# MVP2 ‚Äî Ci√™ncia de Dados

## Compara√ß√£o entre Deep Learning e Machine Learning na Previs√£o de Viola√ß√µes de Dados (2010‚Äì2023)

**Discente:** Evanei Gomes dos Santos
**Docente:** Prof. Dr. Andr√© Luiz Marques Serrano
**Curso:** PPEE/UnB ‚Äî Engenharia El√©trica
**Entrega:** Notebook p√∫blico no Google Colab (link ao final)

---

## Resumo Executivo

Este trabalho compara modelos de **Deep Learning** (LSTM, TCN) e de **Machine Learning**/estat√≠sticos (Prophet, SARIMA, XGBoost) na previs√£o mensal de **viola√ß√µes de dados** por setor organizacional, usando a base **Privacy Rights Clearinghouse ‚Äì Data Breach Chronology** (2010‚Äì2023). A avalia√ß√£o usa **MAPE (%)** como m√©trica principal (complementada por **MAE** e **RMSE**). Em s√≠ntese: modelos de **redes neurais** tendem a apresentar **melhor acur√°cia** em setores com **padr√µes temporais mais complexos**, enquanto **XGBoost** mostra competitividade em s√©ries mais **agregadas** e com **padr√µes suaves**. As conclus√µes e n√∫meros setoriais detalhados constam nas se√ß√µes de **Resultados** e **Conclus√£o**.

---

## 1. Defini√ß√£o do Problema

Viola√ß√µes de dados geram impactos financeiros e reputacionais. O objetivo √© **prever a quantidade mensal** de viola√ß√µes por **tipo de organiza√ß√£o** (ex.: sa√∫de, governo, financeiro), para apoiar decis√µes de preven√ß√£o e resposta.

**Hip√≥teses:**

1. As s√©ries mensais por setor cont√™m sinal suficiente para **prever picos** de incidentes.
2. **DL (LSTM/TCN)** ter√° vantagem em s√©ries **n√£o lineares** e com **intera√ß√µes temporais** de longo alcance, enquanto **XGBoost/Prophet/SARIMA** podem ser mais competitivos em **setores agregados** ou com sazonalidade mais clara.

**Escopo:** Comparativo entre fam√≠lias de modelos, priorizando **acur√°cia preditiva (MAPE)** e **consist√™ncia**.

---

$1

### üîß Snippet ‚Äî Carregamento via URL (Google Sheets/CSV)

```python
import pandas as pd
from urllib.parse import urlparse

# üëâ Cole aqui a URL p√∫blica do Google Sheets (ou um CSV remoto)
URL = "https://docs.google.com/spreadsheets/d/SEU_ID/export?format=xlsx"

# Caso a URL seja do tipo .../edit?usp=sharing, troque por .../export?format=xlsx
if "edit" in URL and "export" not in URL:
    URL = URL.split("/edit")[0] + "/export?format=xlsx"

# Leitura
try:
    df_raw = pd.read_excel(URL)
except Exception:
    # Fallback: CSV
    df_raw = pd.read_csv(URL)

# Visualiza√ß√£o inicial
print(df_raw.head())
```

### üîß Snippet ‚Äî Sele√ß√£o de colunas e padroniza√ß√£o de nomes

```python
# Esperado: uma coluna de data e colunas de setores (BSF, BSO, BSR, EDU, GOV, MED, NGO, UNKN, Total Geral)
# Ajuste o nome da coluna de data conforme o seu arquivo (ex.: 'Date Breach')
DATE_COL = 'Date Breach'
setores = ['BSF','BSO','BSR','EDU','GOV','MED','NGO','UNKN','Total Geral']

# Garantir tipos corretos
import numpy as np
import pandas as pd

df = df_raw.copy()
df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors='coerce')
df = df.dropna(subset=[DATE_COL]).sort_values(DATE_COL)

# For√ßar inteiros n√£o-negativos nos setores
for c in setores:
    if c in df.columns:
        df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0).clip(lower=0).astype(int)
```

---

## 3. Metodologia

**Arquitetura anal√≠tica** (alto n√≠vel):

1. **EDA** e diagn√≥stico de s√©ries;
2. **Prepara√ß√£o** (limpeza, padroniza√ß√£o de datas, filtro temporal 2010‚Äì2023, **reamostragem mensal**, remo√ß√£o de **outliers por IQR**, c√°lculo do **expoente de Hurst** para checar persist√™ncia/aleatoriedade);
3. **Divis√£o treino/teste** com **janela temporal fixa** (hold-out nos √∫ltimos meses), opcionalmente com **valida√ß√£o cruzada temporal** quando cab√≠vel;
4. **Modelagem**: Prophet, SARIMA, XGBoost, LSTM, TCN;
5. **Otimiza√ß√£o** por *grid search* e ajustes finos por fam√≠lia;
6. **Avalia√ß√£o** com MAPE (principal), MAE e RMSE;
7. **Compara√ß√£o** e **an√°lise cr√≠tica** por setor;
8. **Conclus√£o** e pr√≥ximos passos.

**Boas pr√°ticas de reprodutibilidade:** notebook p√∫blico **Colab**; dataset carregado **via URL**; c√©lulas de texto explicando decis√µes; gr√°ficos no pr√≥prio notebook.

---

$1

### üîß Snippet ‚Äî Filtro temporal, agrega√ß√£o mensal e limpeza b√°sica

```python
# Recorte 2010‚Äì2023 e √≠ndice temporal
inicio, fim = pd.Timestamp('2010-01-01'), pd.Timestamp('2023-12-31')
mask = (df[DATE_COL] >= inicio) & (df[DATE_COL] <= fim)
df = df.loc[mask].copy()

# Agrega√ß√£o mensal (soma de incidentes por m√™s)
df['month'] = df[DATE_COL].dt.to_period('M').dt.to_timestamp()
df_mensal = (df.groupby('month')[setores]
               .sum()
               .asfreq('MS')
               .fillna(0)
               .astype(int))

df_mensal.head()
```

### üîß Snippet ‚Äî Tratamento de outliers por IQR (winsoriza√ß√£o por setor)

```python
def winsorize_iqr(s):
    q1, q3 = s.quantile(0.25), s.quantile(0.75)
    iqr = q3 - q1
    low, high = q1 - 1.5*iqr, q3 + 1.5*iqr
    return s.clip(lower=max(0, low), upper=max(high, 0))

for c in setores:
    df_mensal[c] = winsorize_iqr(df_mensal[c])
```

### üîß Snippet ‚Äî Expoente de Hurst (diagn√≥stico)

```python
import numpy as np

def hurst_exponent(ts):
    # Implementa√ß√£o simples de R/S (aproxima√ß√£o)
    ts = np.asarray(ts, dtype=float)
    N = len(ts)
    if N < 20:
        return np.nan
    lags = np.floor(np.logspace(1, np.log10(N/2), num=20)).astype(int)
    tau = []
    for lag in lags:
        diffs = ts[lag:] - ts[:-lag]
        tau.append(np.sqrt(np.std(diffs)))
    # Ajuste log-log
    x = np.log(lags)
    y = np.log(tau)
    H = np.polyfit(x, y, 1)[0]
    return max(min(H, 1.0), 0.0)

for c in setores:
    H = hurst_exponent(df_mensal[c].values)
    print(f"Hurst[{c}]: {H:.2f}")
```

### üîß Snippet ‚Äî Split temporal (treino vs. teste)

```python
TEST_SIZE = 24  # meses

split_idx = len(df_mensal) - TEST_SIZE
train_idx = df_mensal.index[:split_idx]
test_idx  = df_mensal.index[split_idx:]

print(train_idx[0], '‚Üí', train_idx[-1], '| test:', test_idx[0], '‚Üí', test_idx[-1])
```

---

$1

> Abaixo, trechos compactos por fam√≠lia de modelos. Nos notebooks finais, essas fun√ß√µes s√£o chamadas em *loops* por setor, com *grid/tuning* quando aplic√°vel.

### üîß Comum ‚Äî M√©tricas e utilit√°rios

```python
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np
import pandas as pd

def mape(y_true, y_pred, eps=1e-8):
    y_true = np.asarray(y_true, dtype=float)
    y_pred = np.asarray(y_pred, dtype=float)
    denom = np.maximum(np.abs(y_true), eps)
    return np.mean(np.abs((y_true - y_pred) / denom)) * 100

RESULTS = []  # coleciona dicion√°rios de resultados
```

### üîß Prophet

```python
from prophet import Prophet

def run_prophet(serie, test_size=24):
    y = serie.reset_index().rename(columns={'month':'ds', serie.name:'y'})
    train, test = y.iloc[:-test_size], y.iloc[-test_size:]
    m = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)
    m.fit(train)
    future = m.make_future_dataframe(periods=test_size, freq='MS')
    fcst = m.predict(future).tail(test_size)
    y_true = test['y'].values
    y_pred = fcst['yhat'].values
    return {
        'Setor': serie.name,
        'Modelo': 'Prophet',
        'MAE': mean_absolute_error(y_true, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
        'MAPE (%)': mape(y_true, y_pred)
    }
```

### üîß SARIMA (statsmodels)

```python
import itertools
from statsmodels.tsa.statespace.sarimax import SARIMAX

def run_sarima(serie, test_size=24, p=1,d=0,q=1,P=1,D=1,Q=1,s=12):
    y_train = serie.iloc[:-test_size]
    y_test  = serie.iloc[-test_size:]
    model = SARIMAX(y_train, order=(p,d,q), seasonal_order=(P,D,Q,s), enforce_stationarity=False, enforce_invertibility=False)
    res = model.fit(disp=False)
    pred = res.get_forecast(steps=test_size).predicted_mean
    y_true = y_test.values
    y_pred = pred.values
    return {
        'Setor': serie.name,
        'Modelo': 'SARIMA',
        'MAE': mean_absolute_error(y_true, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
        'MAPE (%)': mape(y_true, y_pred)
    }
```

### üîß XGBoost (lags)

```python
from xgboost import XGBRegressor

def make_lagged_df(serie, lags=12):
    df = pd.DataFrame({'y': serie.values}, index=serie.index)
    for L in range(1, lags+1):
        df[f'lag_{L}'] = df['y'].shift(L)
    return df.dropna()

def run_xgb(serie, test_size=24, lags=12):
    df_l = make_lagged_df(serie, lags)
    X, y = df_l.drop(columns=['y']).values, df_l['y'].values
    X_train, X_test = X[:-test_size], X[-test_size:]
    y_train, y_test = y[:-test_size], y[-test_size:]
    model = XGBRegressor(n_estimators=500, max_depth=4, learning_rate=0.05, subsample=0.9, colsample_bytree=0.9, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return {
        'Setor': serie.name,
        'Modelo': 'XGBoost',
        'MAE': mean_absolute_error(y_test, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),
        'MAPE (%)': mape(y_test, y_pred)
    }
```

### üîß LSTM (Keras)

```python
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping

def make_supervised(arr, look_back=12):
    X, y = [], []
    for i in range(len(arr) - look_back):
        X.append(arr[i:i+look_back])
        y.append(arr[i+look_back])
    X, y = np.array(X), np.array(y)
    return X[..., np.newaxis], y  # (samples, timesteps, features=1)

def run_lstm(serie, test_size=24, look_back=12, epochs=200, batch_size=32):
    values = serie.values.astype(float)
    scaler = MinMaxScaler()
    vals = scaler.fit_transform(values.reshape(-1,1)).ravel()

    X, y = make_supervised(vals, look_back)
    X_train, X_test = X[:-test_size], X[-test_size:]
    y_train, y_test = y[:-test_size], y[-test_size:]

    model = Sequential([
        LSTM(64, input_shape=(look_back, 1)),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    es = EarlyStopping(patience=10, restore_best_weights=True, monitor='val_loss')
    model.fit(X_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size, callbacks=[es], verbose=0)

    y_pred = model.predict(X_test).ravel()
    # invers√£o para escala original
    y_test_inv = scaler.inverse_transform(y_test.reshape(-1,1)).ravel()
    y_pred_inv = scaler.inverse_transform(y_pred.reshape(-1,1)).ravel()

    return {
        'Setor': serie.name,
        'Modelo': 'LSTM',
        'MAE': mean_absolute_error(y_test_inv, y_pred_inv),
        'RMSE': np.sqrt(mean_squared_error(y_test_inv, y_pred_inv)),
        'MAPE (%)': mape(y_test_inv, y_pred_inv)
    }
```

### üîß TCN (Temporal Convolutional Network)

```python
from tcn import TCN
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Reutiliza make_supervised do LSTM (mesmo formato)

def run_tcn(serie, test_size=24, look_back=12, epochs=200, batch_size=32):
    values = serie.values.astype(float)
    scaler = MinMaxScaler()
    vals = scaler.fit_transform(values.reshape(-1,1)).ravel()

    X, y = make_supervised(vals, look_back)
    X_train, X_test = X[:-test_size], X[-test_size:]
    y_train, y_test = y[:-test_size], y[-test_size:]

    model = Sequential([
        TCN(nb_filters=64, kernel_size=3, dilations=[1,2,4,8], dropout_rate=0.1, return_sequences=False, input_shape=(look_back,1)),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    es = EarlyStopping(patience=10, restore_best_weights=True, monitor='val_loss')
    model.fit(X_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size, callbacks=[es], verbose=0)

    y_pred = model.predict(X_test).ravel()
    y_test_inv = scaler.inverse_transform(y_test.reshape(-1,1)).ravel()
    y_pred_inv = scaler.inverse_transform(y_pred.reshape(-1,1)).ravel()

    return {
        'Setor': serie.name,
        'Modelo': 'TCN',
        'MAE': mean_absolute_error(y_test_inv, y_pred_inv),
        'RMSE': np.sqrt(mean_squared_error(y_test_inv, y_pred_inv)),
        'MAPE (%)': mape(y_test_inv, y_pred_inv)
    }
```

### üîß Loop por setor e consolida√ß√£o de resultados

```python
RESULTS = []
for c in setores:
    serie = df_mensal[c]
    try:
        RESULTS.append(run_prophet(serie, test_size=TEST_SIZE))
    except Exception as e:
        print(f"Prophet falhou em {c}:", e)
    try:
        RESULTS.append(run_sarima(serie, test_size=TEST_SIZE))
    except Exception as e:
        print(f"SARIMA falhou em {c}:", e)
    try:
        RESULTS.append(run_xgb(serie, test_size=TEST_SIZE))
    except Exception as e:
        print(f"XGB falhou em {c}:", e)
    try:
        RESULTS.append(run_lstm(serie, test_size=TEST_SIZE))
    except Exception as e:
        print(f"LSTM falhou em {c}:", e)
    try:
        RESULTS.append(run_tcn(serie, test_size=TEST_SIZE))
    except Exception as e:
        print(f"TCN falhou em {c}:", e)

import pandas as pd

df_results = pd.DataFrame(RESULTS)
print(df_results.head())
```

---

$1

### üîß Snippet ‚Äî Tabelas, heatmap e melhores por setor

```python
# Tabela geral
summary = (df_results
           .groupby(['Setor','Modelo'])[['MAE','RMSE','MAPE (%)']]
           .mean()
           .reset_index())

# Melhor por setor com base no MAPE
melhores = summary.loc[summary.groupby('Setor')['MAPE (%)'].idxmin()].reset_index(drop=True)
print("
üèÜ Melhor MAPE por setor:
", melhores)

# Heatmap simples (matriz Setor x Modelo com MAPE)
pivot_mape = summary.pivot(index='Setor', columns='Modelo', values='MAPE (%)')
print("
Matriz MAPE (Setor x Modelo):
", pivot_mape.round(2))
```

### üîß Snippet ‚Äî Salvamento padronizado dos CSVs (sem timestamp)

```python
# Salva resultados no /content com nomes est√°veis
summary.to_csv('/content/resultados_comparados.csv', index=False)
melhores.to_csv('/content/melhor_modelo_por_setor.csv', index=False)
pivot_mape.to_csv('/content/heatmap_mape.csv')

print("
üíæ Arquivos salvos em /content:")
print("- resultados_comparados.csv")
print("- melhor_modelo_por_setor.csv")
print("- heatmap_mape.csv")
```

---

## 7. Resultados e Discuss√£o

### 7.1 S√≠ntese por Setor (evid√™ncias dos artefatos)

* **Total Geral:** **XGBoost** com MAPE ‚âà **5,97%** (*alta precis√£o*). Redes **TCN/LSTM** tamb√©m com bom desempenho (‚âà **10‚Äì12%**), por√©m acima do XGBoost nesta s√©rie agregada.
* **UNKN (Desconhecido):** **XGBoost** ‚âà **10,03%** (*boa/alta precis√£o*); **LSTM** ‚âà **11,95%** pr√≥ximo do patamar de boa precis√£o.
* **MED (Sa√∫de):** **TCN** ‚âà **23,52%** (*razo√°vel*), **Prophet** ‚âà **26,54%** (razo√°vel).
* **BSF (Financeiro):** **LSTM** ‚âà **21,14%** (limite entre *razo√°vel* e *boa* dependendo de arredondamento/intervalo).
* **BSO (Outros Neg√≥cios):** **TCN** ‚âà **19,39%** (*boa previs√£o*).
* **EDU (Educa√ß√£o):** **ARIMA** ‚âà **36,74%** (*razo√°vel*).
* **BSR (Varejo):** **MAPE ‚â• 70%** em todas as fam√≠lias (previs√£o **imprecisa**; alta volatilidade).

> *Leitura cr√≠tica:* Em s√©ries **agregadas** (Total Geral) e com **magnitude maior**, o **XGBoost** se destacou; j√° em setores com **padr√µes temporais complexos**, **LSTM/TCN** tendem a **superar** Prophet/SARIMA e, em alguns casos, competir com XGBoost. Diferen√ßas de **split**, **tratamento de outliers** e **escolhas de hiperpar√¢metros** explicam varia√ß√µes pontuais.

### 7.2 Insight pr√°tico

* **Planejamento t√°tico:** adotar **XGBoost** para s√©ries **macro**/agregadas; recorrer a **LSTM/TCN** para **setores espec√≠ficos** com din√¢mica mais **n√£o linear**.
* **Setores cr√≠ticos:** **BSR (Varejo)** exige estrat√©gias alternativas (ex.: modelos hier√°rquicos, *external regressors*, *ensembles* especializados e *regime switching*).

### 7.3 Visualiza√ß√µes previstas no notebook

* **Heatmap de MAPE** (modelos √ó setores).
* **Boxplots** de distribui√ß√£o de erros por modelo.
* **Curvas reais vs. previstas** para setores representativos.

---

## 8. Conclus√£o

1. **N√£o h√° ‚Äúum modelo vencedor‚Äù universal**: a efic√°cia depende do **setor** e da **estrutura** da s√©rie.
2. **XGBoost** foi **muito competitivo** em s√©ries **agregadas** (Total Geral, UNKN).
3. **LSTM/TCN** mostraram **vantagem** em setores **complexos** (MED, BSO; e casos como BSF/UNKN em diferentes prepara√ß√µes).
4. **Prophet/SARIMA** mantiveram-se como **baselines interpret√°veis**, √∫teis para diagn√≥stico e *benchmarking*.
5. Para **produ√ß√£o**, sugere-se um **comit√™ de modelos** (meta-ensemble) com sele√ß√£o por setor, al√©m de **monitoramento de drift** e **retreinamento** peri√≥dico.

**Limita√ß√µes:** disponibilidade e qualidade de r√≥tulos por setor; poss√≠veis mudan√ßas de pol√≠tica de notifica√ß√£o ao longo dos anos; sensibilidade a *outliers*; e varia√ß√µes por *split* temporal.
**Pr√≥ximos passos:** *ensembles* DL+ML, vari√°veis ex√≥genas (ex.: eventos regulat√≥rios), valida√ß√£o com 2024‚Äì2025, e avalia√ß√£o de **intervalos de previs√£o**.

---

## 9. Checklist (MVP2)

**Defini√ß√£o do problema**: descrita nas se√ß√µes 1‚Äì2.
**Hip√≥teses**: claras na Se√ß√£o 1.
**Restri√ß√µes/sele√ß√£o de dados**: per√≠odo 2010‚Äì2023; datas v√°lidas; reamostragem mensal.
**Descri√ß√£o do dataset**: atributos e setores (Se√ß√£o 2).
**Split treino/teste**: hold-out temporal (√∫ltimos meses).
**Cross-validation**: quando aplic√°vel, **TimeSeriesSplit**; caso contr√°rio, justificar hold-out.
**Transforma√ß√µes**: padroniza√ß√£o de datas, reamostragem mensal, IQR, Hurst.
**Feature selection**: para XGBoost, sele√ß√£o impl√≠cita por import√¢ncia; para DL, janela (*look_back*) e engenharia de *lags*.
**Modelagem**: justificativas por fam√≠lia (Se√ß√£o 5).
**Tuning**: *grid search* por modelo/setor.
**M√©tricas**: MAPE/MAE/RMSE (Se√ß√£o 6) + interpreta√ß√£o do MAPE.
**Resultados**: s√≠ntese e gr√°ficos previstos (Se√ß√£o 7).
**Melhor solu√ß√£o**: sele√ß√£o por **setor**; sugerido **comit√™** por contexto.

---

$1

### üîß Snippet ‚Äî Organiza√ß√£o dos artefatos de sa√≠da

```python
# Organiza√ß√£o final dos artefatos gerados no notebook
# (ajuste conforme desejar)
ARQUIVOS = {
    'comparacao_geral': '/content/resultados_comparados.csv',
    'melhores_por_setor': '/content/melhor_modelo_por_setor.csv',
    'heatmap_mape': '/content/heatmap_mape.csv'
}

for k, v in ARQUIVOS.items():
    print(f"{k:>20}: {v}")
```

> **Nota:** Caso prefira salvar no Drive, basta montar o Drive no Colab e alterar os caminhos para `'/content/drive/MyDrive/...'`. Nesta vers√£o mantivemos **nomes fixos (sem timestamp)** em **`/content`**, conforme seu padr√£o.

---

## 11. Refer√™ncias

* Privacy Rights Clearinghouse ‚Äî *Data Breach Chronology*.
* Literatura de s√©ries temporais e ciberseguran√ßa (detalhes no artigo base).
* Materiais de apoio da disciplina (requisitos de entrega e checklist).

---

> **Observa√ß√£o final ao avaliador:** Este documento √© o ‚ÄúrelatoÃÅrio‚Äù em formato Markdown. As c√©lulas de texto do *notebook Colab* repetem as se√ß√µes explicativas, seguidas das c√©lulas de c√≥digo que reproduzem cada etapa (preparo, treino, avalia√ß√£o e gr√°ficos). O *link Colab* e as figuras/CSVs finais ser√£o apontados ao final da execu√ß√£o completa do notebook vfinal.
