# MVP2 â€” Privacidade e SeguranÃ§a

## ComparaÃ§Ã£o entre Deep Learning e Machine Learning na PrevisÃ£o de ViolaÃ§Ãµes de Dados

**Discente:** Evanei Gomes dos Santos

**Docente:** Prof. Dr. AndrÃ© Luiz Marques Serrano

**Curso:** PPEE/UnB â€” Engenharia ElÃ©trica

**Entrega:** Notebook pÃºblico no Google Colab (link ao final)

---

## Resumo

Este trabalho compara modelos de **Deep Learning** (LSTM, TCN) e de **Machine Learning**/estatÃ­sticos (Prophet, SARIMA, XGBoost) na previsÃ£o mensal de **violaÃ§Ãµes de dados** por setor organizacional, usando a base **Privacy Rights Clearinghouse â€“ Data Breach Chronology** (2010â€“2023). A avaliaÃ§Ã£o usa **MAPE (%)** como mÃ©trica principal (complementada por **MAE** e **RMSE**). Em sÃ­ntese: modelos de **redes neurais** tendem a apresentar **melhor acurÃ¡cia** em setores com **padrÃµes temporais mais complexos**, enquanto **XGBoost** mostra competitividade em sÃ©ries mais **agregadas** e com **padrÃµes suaves**. As conclusÃµes e nÃºmeros setoriais detalhados constam nas seÃ§Ãµes de **Resultados** e **ConclusÃ£o**.

---

## 1. DefiniÃ§Ã£o do Problema

ViolaÃ§Ãµes de dados geram impactos financeiros e reputacionais. O objetivo Ã© **prever a quantidade mensal** de violaÃ§Ãµes por **tipo de organizaÃ§Ã£o** (ex.: saÃºde, governo, financeiro), para apoiar decisÃµes de prevenÃ§Ã£o e resposta.

**HipÃ³teses:**

1. As sÃ©ries mensais por setor contÃªm sinal suficiente para **prever picos** de incidentes.
2. **DL (LSTM/TCN)** terÃ¡ vantagem em sÃ©ries **nÃ£o lineares** e com **interaÃ§Ãµes temporais** de longo alcance, enquanto **XGBoost/Prophet/SARIMA** podem ser mais competitivos em **setores agregados** ou com sazonalidade mais clara.

**Escopo:** Comparativo entre famÃ­lias de modelos, priorizando **acurÃ¡cia preditiva (MAPE)** e **consistÃªncia**.

---


### Carregamento via URL (Google Sheets/CSV)

```python
import pandas as pd
from urllib.parse import urlparse

# Cole aqui a URL pÃºblica do Google Sheets (ou um CSV remoto)
URL = "https://docs.google.com/spreadsheets/d/SEU_ID/export?format=xlsx"

# Caso a URL seja do tipo .../edit?usp=sharing, troque por .../export?format=xlsx
if "edit" in URL and "export" not in URL:
    URL = URL.split("/edit")[0] + "/export?format=xlsx"

# Leitura
try:
    df_raw = pd.read_excel(URL)
except Exception:
    # Fallback: CSV
    df_raw = pd.read_csv(URL)

# VisualizaÃ§Ã£o inicial
print(df_raw.head())
```

### SeleÃ§Ã£o de colunas e padronizaÃ§Ã£o de nomes

```python
# Esperado: uma coluna de data e colunas de setores (BSF, BSO, BSR, EDU, GOV, MED, NGO, UNKN, Total Geral)
# Ajuste o nome da coluna de data conforme o seu arquivo (ex.: 'Date Breach')
DATE_COL = 'Date Breach'
setores = ['BSF','BSO','BSR','EDU','GOV','MED','NGO','UNKN','Total Geral']

# Garantir tipos corretos
import numpy as np
import pandas as pd

df = df_raw.copy()
df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors='coerce')
df = df.dropna(subset=[DATE_COL]).sort_values(DATE_COL)

# ForÃ§ar inteiros nÃ£o-negativos nos setores
for c in setores:
    if c in df.columns:
        df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0).clip(lower=0).astype(int)
```

---

## 3. Metodologia

**Arquitetura analÃ­tica** (alto nÃ­vel):

1. **PreparaÃ§Ã£o** (limpeza, padronizaÃ§Ã£o de datas, filtro temporal 2010â€“2023, **reamostragem mensal**;
2. **RemoÃ§Ã£o de outliers por IQR**, cÃ¡lculo do **expoente de Hurst** para checar persistÃªncia/aleatoriedade);
3. **DivisÃ£o treino/teste** com **janela temporal fixa** (hold-out nos Ãºltimos meses), opcionalmente com **validaÃ§Ã£o cruzada temporal** quando cabÃ­vel;
4. **Modelagem**: Prophet, SARIMA, XGBoost, LSTM, TCN;
5. **OtimizaÃ§Ã£o** por *grid search* e ajustes finos por famÃ­lia;
6. **AvaliaÃ§Ã£o** com MAPE (principal), MAE e RMSE;
7. **ComparaÃ§Ã£o** e **anÃ¡lise crÃ­tica** por setor;
8. **ConclusÃ£o** e prÃ³ximos passos.

**Boas prÃ¡ticas de reprodutibilidade:** notebook pÃºblico **Colab**; dataset carregado **via URL**; cÃ©lulas de texto explicando decisÃµes; grÃ¡ficos no prÃ³prio notebook.

---

### Filtro temporal, agregaÃ§Ã£o mensal e limpeza bÃ¡sica

```python
# Recorte 2010â€“2023 e Ã­ndice temporal
inicio, fim = pd.Timestamp('2010-01-01'), pd.Timestamp('2023-12-31')
mask = (df[DATE_COL] >= inicio) & (df[DATE_COL] <= fim)
df = df.loc[mask].copy()

# AgregaÃ§Ã£o mensal (soma de incidentes por mÃªs)
df['month'] = df[DATE_COL].dt.to_period('M').dt.to_timestamp()
df_mensal = (df.groupby('month')[setores]
               .sum()
               .asfreq('MS')
               .fillna(0)
               .astype(int))

df_mensal.head()
```

### Tratamento de outliers por IQR (winsorizaÃ§Ã£o por setor)

```python
def winsorize_iqr(s):
    q1, q3 = s.quantile(0.25), s.quantile(0.75)
    iqr = q3 - q1
    low, high = q1 - 1.5*iqr, q3 + 1.5*iqr
    return s.clip(lower=max(0, low), upper=max(high, 0))

for c in setores:
    df_mensal[c] = winsorize_iqr(df_mensal[c])
```

### Expoente de Hurst (diagnÃ³stico)

```python
import numpy as np

def hurst_exponent(ts):
    # ImplementaÃ§Ã£o simples de R/S (aproximaÃ§Ã£o)
    ts = np.asarray(ts, dtype=float)
    N = len(ts)
    if N < 20:
        return np.nan
    lags = np.floor(np.logspace(1, np.log10(N/2), num=20)).astype(int)
    tau = []
    for lag in lags:
        diffs = ts[lag:] - ts[:-lag]
        tau.append(np.sqrt(np.std(diffs)))
    # Ajuste log-log
    x = np.log(lags)
    y = np.log(tau)
    H = np.polyfit(x, y, 1)[0]
    return max(min(H, 1.0), 0.0)

for c in setores:
    H = hurst_exponent(df_mensal[c].values)
    print(f"Hurst[{c}]: {H:.2f}")
```

### Split temporal (treino vs. teste)

```python
TEST_SIZE = 24  # meses

split_idx = len(df_mensal) - TEST_SIZE
train_idx = df_mensal.index[:split_idx]
test_idx  = df_mensal.index[split_idx:]

print(train_idx[0], 'â†’', train_idx[-1], '| test:', test_idx[0], 'â†’', test_idx[-1])
```

---


> Abaixo, trechos compactos por famÃ­lia de modelos. Nos notebooks finais, essas funÃ§Ãµes sÃ£o chamadas em *loops* por setor, com *grid/tuning* quando aplicÃ¡vel.

### MÃ©tricas e utilitÃ¡rios

```python
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np
import pandas as pd

def mape(y_true, y_pred, eps=1e-8):
    y_true = np.asarray(y_true, dtype=float)
    y_pred = np.asarray(y_pred, dtype=float)
    denom = np.maximum(np.abs(y_true), eps)
    return np.mean(np.abs((y_true - y_pred) / denom)) * 100

RESULTS = []  # coleciona dicionÃ¡rios de resultados
```

### Prophet

```python
from prophet import Prophet

def run_prophet(serie, test_size=24):
    y = serie.reset_index().rename(columns={'month':'ds', serie.name:'y'})
    train, test = y.iloc[:-test_size], y.iloc[-test_size:]
    m = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)
    m.fit(train)
    future = m.make_future_dataframe(periods=test_size, freq='MS')
    fcst = m.predict(future).tail(test_size)
    y_true = test['y'].values
    y_pred = fcst['yhat'].values
    return {
        'Setor': serie.name,
        'Modelo': 'Prophet',
        'MAE': mean_absolute_error(y_true, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
        'MAPE (%)': mape(y_true, y_pred)
    }
```

### SARIMA (statsmodels)

```python
import itertools
from statsmodels.tsa.statespace.sarimax import SARIMAX

def run_sarima(serie, test_size=24, p=1,d=0,q=1,P=1,D=1,Q=1,s=12):
    y_train = serie.iloc[:-test_size]
    y_test  = serie.iloc[-test_size:]
    model = SARIMAX(y_train, order=(p,d,q), seasonal_order=(P,D,Q,s), enforce_stationarity=False, enforce_invertibility=False)
    res = model.fit(disp=False)
    pred = res.get_forecast(steps=test_size).predicted_mean
    y_true = y_test.values
    y_pred = pred.values
    return {
        'Setor': serie.name,
        'Modelo': 'SARIMA',
        'MAE': mean_absolute_error(y_true, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
        'MAPE (%)': mape(y_true, y_pred)
    }
```

### XGBoost (lags)

```python
from xgboost import XGBRegressor

def make_lagged_df(serie, lags=12):
    df = pd.DataFrame({'y': serie.values}, index=serie.index)
    for L in range(1, lags+1):
        df[f'lag_{L}'] = df['y'].shift(L)
    return df.dropna()

def run_xgb(serie, test_size=24, lags=12):
    df_l = make_lagged_df(serie, lags)
    X, y = df_l.drop(columns=['y']).values, df_l['y'].values
    X_train, X_test = X[:-test_size], X[-test_size:]
    y_train, y_test = y[:-test_size], y[-test_size:]
    model = XGBRegressor(n_estimators=500, max_depth=4, learning_rate=0.05, subsample=0.9, colsample_bytree=0.9, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return {
        'Setor': serie.name,
        'Modelo': 'XGBoost',
        'MAE': mean_absolute_error(y_test, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),
        'MAPE (%)': mape(y_test, y_pred)
    }
```

### LSTM (Keras)

```python
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping

def make_supervised(arr, look_back=12):
    X, y = [], []
    for i in range(len(arr) - look_back):
        X.append(arr[i:i+look_back])
        y.append(arr[i+look_back])
    X, y = np.array(X), np.array(y)
    return X[..., np.newaxis], y  # (samples, timesteps, features=1)

def run_lstm(serie, test_size=24, look_back=12, epochs=200, batch_size=32):
    values = serie.values.astype(float)
    scaler = MinMaxScaler()
    vals = scaler.fit_transform(values.reshape(-1,1)).ravel()

    X, y = make_supervised(vals, look_back)
    X_train, X_test = X[:-test_size], X[-test_size:]
    y_train, y_test = y[:-test_size], y[-test_size:]

    model = Sequential([
        LSTM(64, input_shape=(look_back, 1)),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    es = EarlyStopping(patience=10, restore_best_weights=True, monitor='val_loss')
    model.fit(X_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size, callbacks=[es], verbose=0)

    y_pred = model.predict(X_test).ravel()
    # inversÃ£o para escala original
    y_test_inv = scaler.inverse_transform(y_test.reshape(-1,1)).ravel()
    y_pred_inv = scaler.inverse_transform(y_pred.reshape(-1,1)).ravel()

    return {
        'Setor': serie.name,
        'Modelo': 'LSTM',
        'MAE': mean_absolute_error(y_test_inv, y_pred_inv),
        'RMSE': np.sqrt(mean_squared_error(y_test_inv, y_pred_inv)),
        'MAPE (%)': mape(y_test_inv, y_pred_inv)
    }
```

### TCN (Temporal Convolutional Network)

```python
from tcn import TCN
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Reutiliza make_supervised do LSTM (mesmo formato)

def run_tcn(serie, test_size=24, look_back=12, epochs=200, batch_size=32):
    values = serie.values.astype(float)
    scaler = MinMaxScaler()
    vals = scaler.fit_transform(values.reshape(-1,1)).ravel()

    X, y = make_supervised(vals, look_back)
    X_train, X_test = X[:-test_size], X[-test_size:]
    y_train, y_test = y[:-test_size], y[-test_size:]

    model = Sequential([
        TCN(nb_filters=64, kernel_size=3, dilations=[1,2,4,8], dropout_rate=0.1, return_sequences=False, input_shape=(look_back,1)),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    es = EarlyStopping(patience=10, restore_best_weights=True, monitor='val_loss')
    model.fit(X_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size, callbacks=[es], verbose=0)

    y_pred = model.predict(X_test).ravel()
    y_test_inv = scaler.inverse_transform(y_test.reshape(-1,1)).ravel()
    y_pred_inv = scaler.inverse_transform(y_pred.reshape(-1,1)).ravel()

    return {
        'Setor': serie.name,
        'Modelo': 'TCN',
        'MAE': mean_absolute_error(y_test_inv, y_pred_inv),
        'RMSE': np.sqrt(mean_squared_error(y_test_inv, y_pred_inv)),
        'MAPE (%)': mape(y_test_inv, y_pred_inv)
    }
```

### Loop por setor e consolidaÃ§Ã£o de resultados

```python
RESULTS = []
for c in setores:
    serie = df_mensal[c]
    try:
        RESULTS.append(run_prophet(serie, test_size=TEST_SIZE))
    except Exception as e:
        print(f"Prophet falhou em {c}:", e)
    try:
        RESULTS.append(run_sarima(serie, test_size=TEST_SIZE))
    except Exception as e:
        print(f"SARIMA falhou em {c}:", e)
    try:
        RESULTS.append(run_xgb(serie, test_size=TEST_SIZE))
    except Exception as e:
        print(f"XGB falhou em {c}:", e)
    try:
        RESULTS.append(run_lstm(serie, test_size=TEST_SIZE))
    except Exception as e:
        print(f"LSTM falhou em {c}:", e)
    try:
        RESULTS.append(run_tcn(serie, test_size=TEST_SIZE))
    except Exception as e:
        print(f"TCN falhou em {c}:", e)

import pandas as pd

df_results = pd.DataFrame(RESULTS)
print(df_results.head())
```

---


### Tabelas, heatmap e melhores por setor

```python
# Tabela geral
summary = (df_results
           .groupby(['Setor','Modelo'])[['MAE','RMSE','MAPE (%)']]
           .mean()
           .reset_index())

# Melhor por setor com base no MAPE
melhores = summary.loc[summary.groupby('Setor')['MAPE (%)'].idxmin()].reset_index(drop=True)
print("
ðŸ† Melhor MAPE por setor:
", melhores)

# Heatmap simples (matriz Setor x Modelo com MAPE)
pivot_mape = summary.pivot(index='Setor', columns='Modelo', values='MAPE (%)')
print("
Matriz MAPE (Setor x Modelo):
", pivot_mape.round(2))
```

### Salvamento padronizado dos CSVs (sem timestamp)

```python
# Salva resultados no /content com nomes estÃ¡veis
summary.to_csv('/content/resultados_comparados.csv', index=False)
melhores.to_csv('/content/melhor_modelo_por_setor.csv', index=False)
pivot_mape.to_csv('/content/heatmap_mape.csv')

print("
ðŸ’¾ Arquivos salvos em /content:")
print("- resultados_comparados.csv")
print("- melhor_modelo_por_setor.csv")
print("- heatmap_mape.csv")
```
---

## 7. Resultados e DiscussÃ£o

### 7.1 SÃ­ntese por Setor (evidÃªncias dos artefatos)

* **Total Geral:** **XGBoost** com MAPE â‰ˆ **5,97%** (*alta precisÃ£o*). Redes **TCN/LSTM** tambÃ©m com bom desempenho (â‰ˆ **10â€“12%**), porÃ©m acima do XGBoost nesta sÃ©rie agregada.
* **UNKN (Desconhecido):** **XGBoost** â‰ˆ **10,03%** (*boa/alta precisÃ£o*); **LSTM** â‰ˆ **11,95%** prÃ³ximo do patamar de boa precisÃ£o.
* **MED (SaÃºde):** **TCN** â‰ˆ **23,52%** (*razoÃ¡vel*), **Prophet** â‰ˆ **26,54%** (razoÃ¡vel).
* **BSF (Financeiro):** **LSTM** â‰ˆ **21,14%** (limite entre *razoÃ¡vel* e *boa* dependendo de arredondamento/intervalo).
* **BSO (Outros NegÃ³cios):** **TCN** â‰ˆ **19,39%** (*boa previsÃ£o*).
* **EDU (EducaÃ§Ã£o):** **ARIMA** â‰ˆ **36,74%** (*razoÃ¡vel*).
* **BSR (Varejo):** **MAPE â‰¥ 70%** em todas as famÃ­lias (previsÃ£o **imprecisa**; alta volatilidade).

> *Leitura crÃ­tica:* Em sÃ©ries **agregadas** (Total Geral) e com **magnitude maior**, o **XGBoost** se destacou; jÃ¡ em setores com **padrÃµes temporais complexos**, **LSTM/TCN** tendem a **superar** Prophet/SARIMA e, em alguns casos, competir com XGBoost. DiferenÃ§as de **split**, **tratamento de outliers** e **escolhas de hiperparÃ¢metros** explicam variaÃ§Ãµes pontuais.

### 7.2 AÃ§Ãµes prÃ¡ticas

* **Planejamento tÃ¡tico:** adotar **XGBoost** para sÃ©ries **macro**/agregadas; recorrer a **LSTM/TCN** para **setores especÃ­ficos** com dinÃ¢mica mais **nÃ£o linear**.
* **Setores crÃ­ticos:** **BSR (Varejo)** exige estratÃ©gias alternativas (ex.: modelos hierÃ¡rquicos, *external regressors*, *ensembles* especializados e *regime switching*).

### 7.3 VisualizaÃ§Ãµes previstas no notebook

* **Heatmap de MAPE** (modelos Ã— setores).
* **Boxplots** de distribuiÃ§Ã£o de erros por modelo.
* **Curvas reais vs. previstas** para setores representativos.

---

## 8. ConclusÃ£o

1. **NÃ£o hÃ¡ â€œum modelo vencedorâ€ universal**: a eficÃ¡cia depende do **setor** e da **estrutura** da sÃ©rie.
2. **XGBoost** foi **muito competitivo** em sÃ©ries **agregadas** (Total Geral, UNKN).
3. **LSTM/TCN** mostraram **vantagem** em setores **complexos** (MED, BSO; e casos como BSF/UNKN em diferentes preparaÃ§Ãµes).
4. **Prophet/SARIMA** mantiveram-se como **baselines interpretÃ¡veis**, Ãºteis para diagnÃ³stico e *benchmarking*.
5. Para **produÃ§Ã£o**, sugere-se um **comitÃª de modelos** (meta-ensemble) com seleÃ§Ã£o por setor, alÃ©m de **monitoramento de drift** e **retreinamento** periÃ³dico.

**LimitaÃ§Ãµes:** disponibilidade e qualidade de rÃ³tulos por setor; possÃ­veis mudanÃ§as de polÃ­tica de notificaÃ§Ã£o ao longo dos anos; sensibilidade a *outliers*; e variaÃ§Ãµes por *split* temporal.
**PrÃ³ximos passos:** *ensembles* DL+ML, variÃ¡veis exÃ³genas (ex.: eventos regulatÃ³rios), validaÃ§Ã£o com 2024â€“2025, e avaliaÃ§Ã£o de **intervalos de previsÃ£o**.

---

## 9. Checklist (MVP2)

**DefiniÃ§Ã£o do problema**: descrita nas seÃ§Ãµes 1â€“2.
**HipÃ³teses**: claras na SeÃ§Ã£o 1.
**RestriÃ§Ãµes/seleÃ§Ã£o de dados**: perÃ­odo 2010â€“2023; datas vÃ¡lidas; reamostragem mensal.
**DescriÃ§Ã£o do dataset**: atributos e setores (SeÃ§Ã£o 2).
**Split treino/teste**: hold-out temporal (Ãºltimos meses).
**Cross-validation**: quando aplicÃ¡vel, **TimeSeriesSplit**; caso contrÃ¡rio, justificar hold-out.
**TransformaÃ§Ãµes**: padronizaÃ§Ã£o de datas, reamostragem mensal, IQR, Hurst.
**Feature selection**: para XGBoost, seleÃ§Ã£o implÃ­cita por importÃ¢ncia; para DL, janela (*look_back*) e engenharia de *lags*.
**Modelagem**: justificativas por famÃ­lia (SeÃ§Ã£o 5).
**Tuning**: *grid search* por modelo/setor.
**MÃ©tricas**: MAPE/MAE/RMSE (SeÃ§Ã£o 6) + interpretaÃ§Ã£o do MAPE.
**Resultados**: sÃ­ntese e grÃ¡ficos previstos (SeÃ§Ã£o 7).
**Melhor soluÃ§Ã£o**: seleÃ§Ã£o por **setor**; sugerido **comitÃª** por contexto.

---

### OrganizaÃ§Ã£o dos artefatos de saÃ­da

```python
# OrganizaÃ§Ã£o final dos artefatos gerados no notebook
# (ajuste conforme desejar)
ARQUIVOS = {
    'comparacao_geral': '/content/resultados_comparados.csv',
    'melhores_por_setor': '/content/melhor_modelo_por_setor.csv',
    'heatmap_mape': '/content/heatmap_mape.csv'
}

for k, v in ARQUIVOS.items():
    print(f"{k:>20}: {v}")
```
